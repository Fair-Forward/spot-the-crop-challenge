{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Plato_Radiant_Data_Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a2ae7b9-4da2-472b-860d-5acb063242b0"
      },
      "source": [
        "<img src='https://radiant-assets.s3-us-west-2.amazonaws.com/PrimaryRadiantMLHubLogo.png' alt='Radiant MLHub Logo' width='300'/>\n",
        "\n",
        "# A Baseline Model for the Radiant Earth Spot the Crop Challenge [Sentinel-2 version]\n",
        "\n",
        "This notebook walks you through the steps to load the data and build a baseline model based on Sentinel-2 daya using Random Forests for `Radiant Earth Spot the Crop Challenge`."
      ],
      "id": "1a2ae7b9-4da2-472b-860d-5acb063242b0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5894a1e0-23f6-4f8d-940b-1317fba1e762"
      },
      "source": [
        "## Radiant MLHub API\n",
        "\n",
        "\n",
        "The Radiant MLHub API gives access to open Earth imagery training data for machine learning applications. You can learn more about the repository at the [Radiant MLHub site](https://mlhub.earth) and about the organization behind it at the [Radiant Earth Foundation site](https://radiant.earth).\n",
        "\n",
        "Full documentation for the API is available at [docs.mlhub.earth](docs.mlhub.earth).\n",
        "\n",
        "Each item in our collection is explained in json format compliant with [STAC](https://stacspec.org/) [label extension](https://github.com/radiantearth/stac-spec/tree/master/extensions/label) definition."
      ],
      "id": "5894a1e0-23f6-4f8d-940b-1317fba1e762"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "973f1d8d-12cd-4661-9cf5-c50ecb9b2ab6"
      },
      "source": [
        "## Dependencies\n",
        "\n",
        "All the dependencies for this notebook are included in the `requirements.txt` file included in this folder.\n"
      ],
      "id": "973f1d8d-12cd-4661-9cf5-c50ecb9b2ab6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "210d52cd-d81e-446b-8a87-2b0a6cac3bae"
      },
      "source": [
        "**You must replace the `YOUR_API_KEY_HERE` text with your API key which you can obtain by creating a free account on the [MLHub Dashboard](https://dashboard.mlhub.earth/) within the `API Keys` tab at the top of the page.**"
      ],
      "id": "210d52cd-d81e-446b-8a87-2b0a6cac3bae"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t6TmGk6d7Hn",
        "outputId": "0170e638-3390-49fd-d0e2-b663a59f9261"
      },
      "source": [
        "!pip install --quiet -r /content/Plato_Radiant_Data_Preprocessing_requirements.txt"
      ],
      "id": "9t6TmGk6d7Hn",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 19.3 MB 3.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5ec7942-db89-4039-9065-555c6a5775aa"
      },
      "source": [
        "import datetime\n",
        "from datetime import timedelta\n",
        "import rasterio\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "a5ec7942-db89-4039-9065-555c6a5775aa",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrZqwdgvoKxy"
      },
      "source": [
        "competition_train_df = pd.read_csv('train_df.csv').sort_values(by = 'tile_id').reset_index(drop = True)\n",
        "competition_test_df = pd.read_csv('test_df.csv').sort_values(by = 'tile_id').reset_index(drop = True)"
      ],
      "id": "QrZqwdgvoKxy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "woWkugqsodA3",
        "outputId": "6c40c585-659d-4ba6-bcde-4872a8db874c"
      },
      "source": [
        "competition_train_df.head()"
      ],
      "id": "woWkugqsodA3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile_id</th>\n",
              "      <th>datetime</th>\n",
              "      <th>satellite_platform</th>\n",
              "      <th>asset</th>\n",
              "      <th>file_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-06-20</td>\n",
              "      <td>s2</td>\n",
              "      <td>B11</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-14</td>\n",
              "      <td>s2</td>\n",
              "      <td>B05</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-14</td>\n",
              "      <td>s2</td>\n",
              "      <td>B04</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-11</td>\n",
              "      <td>s2</td>\n",
              "      <td>B06</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-05-11</td>\n",
              "      <td>s2</td>\n",
              "      <td>B05</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile_id    datetime  ... asset                                          file_path\n",
              "0        1  2017-06-20  ...   B11  /content/radiant/ref_south_africa_crops_compet...\n",
              "1        1  2017-05-14  ...   B05  /content/radiant/ref_south_africa_crops_compet...\n",
              "2        1  2017-05-14  ...   B04  /content/radiant/ref_south_africa_crops_compet...\n",
              "3        1  2017-05-11  ...   B06  /content/radiant/ref_south_africa_crops_compet...\n",
              "4        1  2017-05-11  ...   B05  /content/radiant/ref_south_africa_crops_compet...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "m5_sh9foqI1w",
        "outputId": "cf640ceb-01eb-4d90-d73c-965d92aeae84"
      },
      "source": [
        "competition_test_df.head()"
      ],
      "id": "m5_sh9foqI1w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile_id</th>\n",
              "      <th>datetime</th>\n",
              "      <th>satellite_platform</th>\n",
              "      <th>asset</th>\n",
              "      <th>file_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>field_info_test</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>s2</td>\n",
              "      <td>B01</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>s2</td>\n",
              "      <td>B02</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-12</td>\n",
              "      <td>s2</td>\n",
              "      <td>B03</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2017-11-17</td>\n",
              "      <td>s2</td>\n",
              "      <td>B01</td>\n",
              "      <td>/content/radiant/ref_south_africa_crops_compet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile_id  ...                                          file_path\n",
              "0        1  ...  /content/radiant/ref_south_africa_crops_compet...\n",
              "1        1  ...  /content/radiant/ref_south_africa_crops_compet...\n",
              "2        1  ...  /content/radiant/ref_south_africa_crops_compet...\n",
              "3        1  ...  /content/radiant/ref_south_africa_crops_compet...\n",
              "4        1  ...  /content/radiant/ref_south_africa_crops_compet...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bd68551-758a-482f-b022-f6ce59bc27e0",
        "outputId": "6eaae258-7692-4f76-b51d-420edeeebc79"
      },
      "source": [
        "# This DataFrame lists all types of assets including documentation of the data. \n",
        "# In the following, we will use the Sentinel-2 bands as well as labels. \n",
        "competition_train_df['asset'].unique()"
      ],
      "id": "6bd68551-758a-482f-b022-f6ce59bc27e0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['B11', 'B05', 'B04', 'B06', 'raster_values', 'labels', 'B09',\n",
              "       'B12', 'CLM', 'field_info_train', 'field_ids', 'documentation',\n",
              "       'B07', 'B08', 'B8A', 'B02', 'B03', 'B01', 'VV', 'VH'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHm79NMcqgcW"
      },
      "source": [
        "### Date Analysis for S2"
      ],
      "id": "zHm79NMcqgcW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwUIT3zmqfbE"
      },
      "source": [
        "# Change to datetime object\n",
        "competition_train_df.datetime = pd.to_datetime(competition_train_df.datetime)\n",
        "\n",
        "# Check number of unique dates for each tile train\n",
        "train_unique_dates, train_nunique_dates = [], []\n",
        "for tile in competition_train_df.tile_id.unique():\n",
        "  train_unique_dates.append(competition_train_df[(competition_train_df.tile_id == tile) & (competition_train_df.satellite_platform == 's2')].datetime.unique())\n",
        "  train_nunique_dates.append(competition_train_df[(competition_train_df.tile_id == tile) & (competition_train_df.satellite_platform == 's2')].datetime.nunique())\n",
        "\n",
        "# Check number of unique dates for each tile test\n",
        "test_unique_dates, test_nunique_dates = [], []\n",
        "for tile in competition_test_df.tile_id.unique():\n",
        "  test_unique_dates.append(competition_test_df[(competition_test_df.tile_id == tile) & (competition_test_df.satellite_platform == 's2')].datetime.unique())\n",
        "  test_nunique_dates.append(competition_test_df[(competition_test_df.tile_id == tile) & (competition_test_df.satellite_platform == 's2')].datetime.nunique())"
      ],
      "id": "vwUIT3zmqfbE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9htW2Z29qfXf",
        "outputId": "bdcbfd3b-ad32-429a-db7c-09e682dd4884"
      },
      "source": [
        "pd.Series(train_nunique_dates + test_nunique_dates).describe()"
      ],
      "id": "9htW2Z29qfXf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    3787.000000\n",
              "mean       54.447056\n",
              "std        18.647749\n",
              "min        37.000000\n",
              "25%        38.000000\n",
              "50%        38.000000\n",
              "75%        76.000000\n",
              "max        76.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI1LB_c2sIWP"
      },
      "source": [
        " - In total there are 3787 tiles\n",
        " - Average number of dates per tile is 54\n",
        " - Minimum dates available in a tile is 37\n",
        " - Maximum dates available in a tile is 76"
      ],
      "id": "UI1LB_c2sIWP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "_xaubRiIqfVq",
        "outputId": "770100da-a568-4827-ee26-31ce49605ba7"
      },
      "source": [
        "dates_df =pd.DataFrame({\n",
        "                        'tile': competition_train_df.tile_id.unique().tolist()+competition_test_df.tile_id.unique().tolist(),\n",
        "                        'n_unique_dates': train_nunique_dates + test_nunique_dates,\n",
        "                        'unique_dates': train_unique_dates + test_unique_dates\n",
        "                        })\n",
        "dates_df.head()"
      ],
      "id": "_xaubRiIqfVq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile</th>\n",
              "      <th>n_unique_dates</th>\n",
              "      <th>unique_dates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-06-20T00:00:00.000000000, 2017-05-14T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-25T00:00:00.000000000, 2017-07-23T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-08T00:00:00.000000000, 2017-07-05T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-10-03T00:00:00.000000000, 2017-10-13T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-05-11T00:00:00.000000000, 2017-05-21T00:...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile  n_unique_dates                                       unique_dates\n",
              "0     1              76  [2017-06-20T00:00:00.000000000, 2017-05-14T00:...\n",
              "1     2              76  [2017-07-25T00:00:00.000000000, 2017-07-23T00:...\n",
              "2     3              76  [2017-07-08T00:00:00.000000000, 2017-07-05T00:...\n",
              "3     4              38  [2017-10-03T00:00:00.000000000, 2017-10-13T00:...\n",
              "4     5              38  [2017-05-11T00:00:00.000000000, 2017-05-21T00:..."
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfAVrMoQqfTX",
        "outputId": "62bfe367-2666-43de-cbe9-bc3e3b33ae89"
      },
      "source": [
        "all_dates = [item for sublist in dates_df.unique_dates.tolist() for item in sublist]\n",
        "\n",
        "# Number of unique dates overall\n",
        "len(set(all_dates)), set(all_dates)"
      ],
      "id": "KfAVrMoQqfTX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(152,\n",
              " {'2017-04-01',\n",
              "  numpy.datetime64('2017-04-01T00:00:00.000000000'),\n",
              "  '2017-04-04',\n",
              "  numpy.datetime64('2017-04-04T00:00:00.000000000'),\n",
              "  '2017-04-11',\n",
              "  numpy.datetime64('2017-04-11T00:00:00.000000000'),\n",
              "  '2017-04-14',\n",
              "  numpy.datetime64('2017-04-14T00:00:00.000000000'),\n",
              "  '2017-04-21',\n",
              "  numpy.datetime64('2017-04-21T00:00:00.000000000'),\n",
              "  '2017-04-24',\n",
              "  numpy.datetime64('2017-04-24T00:00:00.000000000'),\n",
              "  '2017-05-01',\n",
              "  numpy.datetime64('2017-05-01T00:00:00.000000000'),\n",
              "  '2017-05-04',\n",
              "  numpy.datetime64('2017-05-04T00:00:00.000000000'),\n",
              "  '2017-05-11',\n",
              "  numpy.datetime64('2017-05-11T00:00:00.000000000'),\n",
              "  '2017-05-14',\n",
              "  numpy.datetime64('2017-05-14T00:00:00.000000000'),\n",
              "  '2017-05-21',\n",
              "  numpy.datetime64('2017-05-21T00:00:00.000000000'),\n",
              "  '2017-05-24',\n",
              "  numpy.datetime64('2017-05-24T00:00:00.000000000'),\n",
              "  '2017-05-31',\n",
              "  numpy.datetime64('2017-05-31T00:00:00.000000000'),\n",
              "  '2017-06-03',\n",
              "  numpy.datetime64('2017-06-03T00:00:00.000000000'),\n",
              "  '2017-06-10',\n",
              "  numpy.datetime64('2017-06-10T00:00:00.000000000'),\n",
              "  '2017-06-13',\n",
              "  numpy.datetime64('2017-06-13T00:00:00.000000000'),\n",
              "  '2017-06-20',\n",
              "  numpy.datetime64('2017-06-20T00:00:00.000000000'),\n",
              "  '2017-06-23',\n",
              "  numpy.datetime64('2017-06-23T00:00:00.000000000'),\n",
              "  '2017-06-30',\n",
              "  numpy.datetime64('2017-06-30T00:00:00.000000000'),\n",
              "  '2017-07-03',\n",
              "  numpy.datetime64('2017-07-03T00:00:00.000000000'),\n",
              "  '2017-07-05',\n",
              "  numpy.datetime64('2017-07-05T00:00:00.000000000'),\n",
              "  '2017-07-08',\n",
              "  numpy.datetime64('2017-07-08T00:00:00.000000000'),\n",
              "  '2017-07-10',\n",
              "  numpy.datetime64('2017-07-10T00:00:00.000000000'),\n",
              "  '2017-07-13',\n",
              "  numpy.datetime64('2017-07-13T00:00:00.000000000'),\n",
              "  '2017-07-15',\n",
              "  numpy.datetime64('2017-07-15T00:00:00.000000000'),\n",
              "  '2017-07-18',\n",
              "  numpy.datetime64('2017-07-18T00:00:00.000000000'),\n",
              "  '2017-07-20',\n",
              "  numpy.datetime64('2017-07-20T00:00:00.000000000'),\n",
              "  '2017-07-23',\n",
              "  numpy.datetime64('2017-07-23T00:00:00.000000000'),\n",
              "  '2017-07-25',\n",
              "  numpy.datetime64('2017-07-25T00:00:00.000000000'),\n",
              "  '2017-07-28',\n",
              "  numpy.datetime64('2017-07-28T00:00:00.000000000'),\n",
              "  '2017-07-30',\n",
              "  numpy.datetime64('2017-07-30T00:00:00.000000000'),\n",
              "  '2017-08-02',\n",
              "  numpy.datetime64('2017-08-02T00:00:00.000000000'),\n",
              "  '2017-08-04',\n",
              "  numpy.datetime64('2017-08-04T00:00:00.000000000'),\n",
              "  '2017-08-07',\n",
              "  numpy.datetime64('2017-08-07T00:00:00.000000000'),\n",
              "  '2017-08-09',\n",
              "  numpy.datetime64('2017-08-09T00:00:00.000000000'),\n",
              "  '2017-08-12',\n",
              "  numpy.datetime64('2017-08-12T00:00:00.000000000'),\n",
              "  '2017-08-14',\n",
              "  numpy.datetime64('2017-08-14T00:00:00.000000000'),\n",
              "  '2017-08-17',\n",
              "  numpy.datetime64('2017-08-17T00:00:00.000000000'),\n",
              "  '2017-08-19',\n",
              "  numpy.datetime64('2017-08-19T00:00:00.000000000'),\n",
              "  '2017-08-22',\n",
              "  numpy.datetime64('2017-08-22T00:00:00.000000000'),\n",
              "  '2017-08-24',\n",
              "  numpy.datetime64('2017-08-24T00:00:00.000000000'),\n",
              "  '2017-08-27',\n",
              "  numpy.datetime64('2017-08-27T00:00:00.000000000'),\n",
              "  '2017-08-29',\n",
              "  numpy.datetime64('2017-08-29T00:00:00.000000000'),\n",
              "  '2017-09-01',\n",
              "  numpy.datetime64('2017-09-01T00:00:00.000000000'),\n",
              "  '2017-09-06',\n",
              "  numpy.datetime64('2017-09-06T00:00:00.000000000'),\n",
              "  '2017-09-08',\n",
              "  numpy.datetime64('2017-09-08T00:00:00.000000000'),\n",
              "  '2017-09-11',\n",
              "  numpy.datetime64('2017-09-11T00:00:00.000000000'),\n",
              "  '2017-09-18',\n",
              "  numpy.datetime64('2017-09-18T00:00:00.000000000'),\n",
              "  '2017-09-21',\n",
              "  numpy.datetime64('2017-09-21T00:00:00.000000000'),\n",
              "  '2017-09-23',\n",
              "  numpy.datetime64('2017-09-23T00:00:00.000000000'),\n",
              "  '2017-09-26',\n",
              "  numpy.datetime64('2017-09-26T00:00:00.000000000'),\n",
              "  '2017-09-28',\n",
              "  numpy.datetime64('2017-09-28T00:00:00.000000000'),\n",
              "  '2017-10-01',\n",
              "  numpy.datetime64('2017-10-01T00:00:00.000000000'),\n",
              "  '2017-10-03',\n",
              "  numpy.datetime64('2017-10-03T00:00:00.000000000'),\n",
              "  '2017-10-06',\n",
              "  numpy.datetime64('2017-10-06T00:00:00.000000000'),\n",
              "  '2017-10-08',\n",
              "  numpy.datetime64('2017-10-08T00:00:00.000000000'),\n",
              "  '2017-10-11',\n",
              "  numpy.datetime64('2017-10-11T00:00:00.000000000'),\n",
              "  '2017-10-13',\n",
              "  numpy.datetime64('2017-10-13T00:00:00.000000000'),\n",
              "  '2017-10-16',\n",
              "  numpy.datetime64('2017-10-16T00:00:00.000000000'),\n",
              "  '2017-10-18',\n",
              "  numpy.datetime64('2017-10-18T00:00:00.000000000'),\n",
              "  '2017-10-21',\n",
              "  numpy.datetime64('2017-10-21T00:00:00.000000000'),\n",
              "  '2017-10-23',\n",
              "  numpy.datetime64('2017-10-23T00:00:00.000000000'),\n",
              "  '2017-10-26',\n",
              "  numpy.datetime64('2017-10-26T00:00:00.000000000'),\n",
              "  '2017-10-28',\n",
              "  numpy.datetime64('2017-10-28T00:00:00.000000000'),\n",
              "  '2017-10-31',\n",
              "  numpy.datetime64('2017-10-31T00:00:00.000000000'),\n",
              "  '2017-11-02',\n",
              "  numpy.datetime64('2017-11-02T00:00:00.000000000'),\n",
              "  '2017-11-05',\n",
              "  numpy.datetime64('2017-11-05T00:00:00.000000000'),\n",
              "  '2017-11-07',\n",
              "  numpy.datetime64('2017-11-07T00:00:00.000000000'),\n",
              "  '2017-11-10',\n",
              "  numpy.datetime64('2017-11-10T00:00:00.000000000'),\n",
              "  '2017-11-12',\n",
              "  numpy.datetime64('2017-11-12T00:00:00.000000000'),\n",
              "  '2017-11-15',\n",
              "  numpy.datetime64('2017-11-15T00:00:00.000000000'),\n",
              "  '2017-11-17',\n",
              "  numpy.datetime64('2017-11-17T00:00:00.000000000'),\n",
              "  '2017-11-20',\n",
              "  numpy.datetime64('2017-11-20T00:00:00.000000000'),\n",
              "  '2017-11-22',\n",
              "  numpy.datetime64('2017-11-22T00:00:00.000000000'),\n",
              "  '2017-11-27',\n",
              "  numpy.datetime64('2017-11-27T00:00:00.000000000'),\n",
              "  '2017-11-30',\n",
              "  numpy.datetime64('2017-11-30T00:00:00.000000000')})"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPaA9FJKqfP-",
        "outputId": "78426bd8-faee-40d4-de43-103a80ff59bf"
      },
      "source": [
        "# Maximum and minimum dates \n",
        "pd.Series(all_dates).min(), pd.Series(all_dates).max()"
      ],
      "id": "yPaA9FJKqfP-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Timestamp('2017-04-01 00:00:00'), Timestamp('2017-11-30 00:00:00'))"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lKQcModqfNL",
        "outputId": "8cae5976-0836-486e-8f7c-45548d27880f"
      },
      "source": [
        "# Investigate minimum dates\n",
        "min_dates = dates_df[dates_df.n_unique_dates == 37].unique_dates.tolist()\n",
        "min_dates"
      ],
      "id": "7lKQcModqfNL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['2017-11-27T00:00:00.000000000', '2017-11-17T00:00:00.000000000',\n",
              "        '2017-11-07T00:00:00.000000000', '2017-11-12T00:00:00.000000000',\n",
              "        '2017-11-22T00:00:00.000000000', '2017-05-11T00:00:00.000000000',\n",
              "        '2017-05-21T00:00:00.000000000', '2017-05-31T00:00:00.000000000',\n",
              "        '2017-06-10T00:00:00.000000000', '2017-06-20T00:00:00.000000000',\n",
              "        '2017-05-01T00:00:00.000000000', '2017-04-01T00:00:00.000000000',\n",
              "        '2017-04-11T00:00:00.000000000', '2017-04-21T00:00:00.000000000',\n",
              "        '2017-10-28T00:00:00.000000000', '2017-11-02T00:00:00.000000000',\n",
              "        '2017-07-25T00:00:00.000000000', '2017-07-30T00:00:00.000000000',\n",
              "        '2017-08-04T00:00:00.000000000', '2017-07-20T00:00:00.000000000',\n",
              "        '2017-08-09T00:00:00.000000000', '2017-08-19T00:00:00.000000000',\n",
              "        '2017-07-15T00:00:00.000000000', '2017-06-30T00:00:00.000000000',\n",
              "        '2017-07-05T00:00:00.000000000', '2017-07-10T00:00:00.000000000',\n",
              "        '2017-10-23T00:00:00.000000000', '2017-10-18T00:00:00.000000000',\n",
              "        '2017-10-13T00:00:00.000000000', '2017-10-08T00:00:00.000000000',\n",
              "        '2017-10-03T00:00:00.000000000', '2017-09-28T00:00:00.000000000',\n",
              "        '2017-09-23T00:00:00.000000000', '2017-09-08T00:00:00.000000000',\n",
              "        '2017-08-29T00:00:00.000000000', '2017-08-24T00:00:00.000000000',\n",
              "        '2017-09-18T00:00:00.000000000'], dtype='datetime64[ns]')]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKOHEG-w2NWw",
        "outputId": "89be0046-d4bb-4a01-a62b-2bb31eb9d08c"
      },
      "source": [
        "# Data provided is for every 5 days\n",
        "# Confirmation of 5 day difference\n",
        "for i in range(5):\n",
        "  print(pd.to_datetime(min_dates[0][i]) + timedelta(days = 5))"
      ],
      "id": "iKOHEG-w2NWw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017-12-02 00:00:00\n",
            "2017-11-22 00:00:00\n",
            "2017-11-12 00:00:00\n",
            "2017-11-17 00:00:00\n",
            "2017-11-27 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKydgboF6nSR"
      },
      "source": [
        " - Some dates are not available for 5 day difference"
      ],
      "id": "kKydgboF6nSR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EESxdtB06kNk",
        "outputId": "2effb8b3-d571-4236-b2c2-b72307a475ea"
      },
      "source": [
        "# Confirmation of 10 day difference\n",
        "for i in range(5):\n",
        "  print(pd.to_datetime(min_dates[0][i]) + timedelta(days = 10))"
      ],
      "id": "EESxdtB06kNk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2017-12-07 00:00:00\n",
            "2017-11-27 00:00:00\n",
            "2017-11-17 00:00:00\n",
            "2017-11-22 00:00:00\n",
            "2017-12-02 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol0SeNOU602L"
      },
      "source": [
        " - Most days are available for a ten day difference"
      ],
      "id": "Ol0SeNOU602L"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "X6fsg0pV66R_",
        "outputId": "8cf1a62c-5240-4ccd-9575-8d9b4069019e"
      },
      "source": [
        "# Confirm that each tile has a difference of 10 days\n",
        "dates_df.head()"
      ],
      "id": "X6fsg0pV66R_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile</th>\n",
              "      <th>n_unique_dates</th>\n",
              "      <th>unique_dates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-06-20T00:00:00.000000000, 2017-05-14T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-25T00:00:00.000000000, 2017-07-23T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-08T00:00:00.000000000, 2017-07-05T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-10-03T00:00:00.000000000, 2017-10-13T00:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-05-11T00:00:00.000000000, 2017-05-21T00:...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile  n_unique_dates                                       unique_dates\n",
              "0     1              76  [2017-06-20T00:00:00.000000000, 2017-05-14T00:...\n",
              "1     2              76  [2017-07-25T00:00:00.000000000, 2017-07-23T00:...\n",
              "2     3              76  [2017-07-08T00:00:00.000000000, 2017-07-05T00:...\n",
              "3     4              38  [2017-10-03T00:00:00.000000000, 2017-10-13T00:...\n",
              "4     5              38  [2017-05-11T00:00:00.000000000, 2017-05-21T00:..."
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "dOWk1aPe7LR7",
        "outputId": "29fd4848-a645-4e6f-d83c-ae7e2d92ca66"
      },
      "source": [
        "# Check minimum and maximum dates for each tile\n",
        "dates_min, dates_max = [], []\n",
        "for i in range(dates_df.shape[0]):\n",
        "  dates_min.append(dates_df.unique_dates.loc[i].min())\n",
        "  dates_max.append(dates_df.unique_dates.loc[i].max())\n",
        "\n",
        "dates_df['min_date'] = dates_min\n",
        "dates_df['max_date'] = dates_max\n",
        "dates_df.head()"
      ],
      "id": "dOWk1aPe7LR7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile</th>\n",
              "      <th>n_unique_dates</th>\n",
              "      <th>unique_dates</th>\n",
              "      <th>min_date</th>\n",
              "      <th>max_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-06-20T00:00:00.000000000, 2017-05-14T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-25T00:00:00.000000000, 2017-07-23T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-08T00:00:00.000000000, 2017-07-05T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-10-03T00:00:00.000000000, 2017-10-13T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-05-11T00:00:00.000000000, 2017-05-21T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile  n_unique_dates  ...   min_date   max_date\n",
              "0     1              76  ... 2017-04-01 2017-11-30\n",
              "1     2              76  ... 2017-04-01 2017-11-30\n",
              "2     3              76  ... 2017-04-01 2017-11-30\n",
              "3     4              38  ... 2017-04-01 2017-11-27\n",
              "4     5              38  ... 2017-04-01 2017-11-27\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlFhO6ST7LPA",
        "outputId": "ac5d37dc-a5c2-4076-c918-d72303fbf10b"
      },
      "source": [
        "dates_df.min_date.unique(), dates_df.max_date.unique()"
      ],
      "id": "MlFhO6ST7LPA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['2017-04-01T00:00:00.000000000', '2017-04-04T00:00:00.000000000'],\n",
              "       dtype='datetime64[ns]'),\n",
              " array(['2017-11-30T00:00:00.000000000', '2017-11-27T00:00:00.000000000'],\n",
              "       dtype='datetime64[ns]'))"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1K5sFPB8R90"
      },
      "source": [
        " - There are two unique start and end dates for tiles"
      ],
      "id": "j1K5sFPB8R90"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT54FScq7LJ6",
        "outputId": "99972927-fe87-4497-fc88-8594a2cf1394"
      },
      "source": [
        "# Create 10  day difference dates for each tile given the start day\n",
        "# There are 24 10 day gaps between start and end dates\n",
        "# if first date is 2017-04-01\n",
        "start_date = pd.to_datetime('2017-04-01')\n",
        "dates_1 = []\n",
        "dates_1.append(start_date)\n",
        "for i in range(24):\n",
        " start_date = start_date + timedelta(days = 10)\n",
        " dates_1.append(start_date)\n",
        "dates_1"
      ],
      "id": "UT54FScq7LJ6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Timestamp('2017-04-01 00:00:00'),\n",
              " Timestamp('2017-04-11 00:00:00'),\n",
              " Timestamp('2017-04-21 00:00:00'),\n",
              " Timestamp('2017-05-01 00:00:00'),\n",
              " Timestamp('2017-05-11 00:00:00'),\n",
              " Timestamp('2017-05-21 00:00:00'),\n",
              " Timestamp('2017-05-31 00:00:00'),\n",
              " Timestamp('2017-06-10 00:00:00'),\n",
              " Timestamp('2017-06-20 00:00:00'),\n",
              " Timestamp('2017-06-30 00:00:00'),\n",
              " Timestamp('2017-07-10 00:00:00'),\n",
              " Timestamp('2017-07-20 00:00:00'),\n",
              " Timestamp('2017-07-30 00:00:00'),\n",
              " Timestamp('2017-08-09 00:00:00'),\n",
              " Timestamp('2017-08-19 00:00:00'),\n",
              " Timestamp('2017-08-29 00:00:00'),\n",
              " Timestamp('2017-09-08 00:00:00'),\n",
              " Timestamp('2017-09-18 00:00:00'),\n",
              " Timestamp('2017-09-28 00:00:00'),\n",
              " Timestamp('2017-10-08 00:00:00'),\n",
              " Timestamp('2017-10-18 00:00:00'),\n",
              " Timestamp('2017-10-28 00:00:00'),\n",
              " Timestamp('2017-11-07 00:00:00'),\n",
              " Timestamp('2017-11-17 00:00:00'),\n",
              " Timestamp('2017-11-27 00:00:00')]"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcK3IMKI_O-S",
        "outputId": "be0b161d-83a5-4da3-8a02-fed78ce622b5"
      },
      "source": [
        "start_date = pd.to_datetime('2017-04-04')\n",
        "dates_2 = []\n",
        "dates_2.append(start_date)\n",
        "for i in range(24):\n",
        " start_date = start_date + timedelta(days = 10)\n",
        " dates_2.append(start_date)\n",
        "dates_2"
      ],
      "id": "IcK3IMKI_O-S",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Timestamp('2017-04-04 00:00:00'),\n",
              " Timestamp('2017-04-14 00:00:00'),\n",
              " Timestamp('2017-04-24 00:00:00'),\n",
              " Timestamp('2017-05-04 00:00:00'),\n",
              " Timestamp('2017-05-14 00:00:00'),\n",
              " Timestamp('2017-05-24 00:00:00'),\n",
              " Timestamp('2017-06-03 00:00:00'),\n",
              " Timestamp('2017-06-13 00:00:00'),\n",
              " Timestamp('2017-06-23 00:00:00'),\n",
              " Timestamp('2017-07-03 00:00:00'),\n",
              " Timestamp('2017-07-13 00:00:00'),\n",
              " Timestamp('2017-07-23 00:00:00'),\n",
              " Timestamp('2017-08-02 00:00:00'),\n",
              " Timestamp('2017-08-12 00:00:00'),\n",
              " Timestamp('2017-08-22 00:00:00'),\n",
              " Timestamp('2017-09-01 00:00:00'),\n",
              " Timestamp('2017-09-11 00:00:00'),\n",
              " Timestamp('2017-09-21 00:00:00'),\n",
              " Timestamp('2017-10-01 00:00:00'),\n",
              " Timestamp('2017-10-11 00:00:00'),\n",
              " Timestamp('2017-10-21 00:00:00'),\n",
              " Timestamp('2017-10-31 00:00:00'),\n",
              " Timestamp('2017-11-10 00:00:00'),\n",
              " Timestamp('2017-11-20 00:00:00'),\n",
              " Timestamp('2017-11-30 00:00:00')]"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "5j7Y9OmC_iyo",
        "outputId": "083dbcb3-5704-48e1-e6d2-b6545f910c23"
      },
      "source": [
        "s_dates = []\n",
        "for i in dates_df.min_date:\n",
        "  if i == pd.to_datetime('2017-04-01'):\n",
        "    s_dates.append(dates_1)\n",
        "  else:\n",
        "    s_dates.append(dates_2)\n",
        "\n",
        "dates_df['expected_dates'] = s_dates\n",
        "dates_df.head()"
      ],
      "id": "5j7Y9OmC_iyo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile</th>\n",
              "      <th>n_unique_dates</th>\n",
              "      <th>unique_dates</th>\n",
              "      <th>min_date</th>\n",
              "      <th>max_date</th>\n",
              "      <th>expected_dates</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-06-20T00:00:00.000000000, 2017-05-14T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-25T00:00:00.000000000, 2017-07-23T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-08T00:00:00.000000000, 2017-07-05T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-10-03T00:00:00.000000000, 2017-10-13T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-27</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-05-11T00:00:00.000000000, 2017-05-21T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-27</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile  ...                                     expected_dates\n",
              "0     1  ...  [2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...\n",
              "1     2  ...  [2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...\n",
              "2     3  ...  [2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...\n",
              "3     4  ...  [2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...\n",
              "4     5  ...  [2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEMzyACB_iuy"
      },
      "source": [
        "# Confirm that unique dates are in expected dates\n",
        "unavailable_dates = []\n",
        "for i in range(dates_df.shape[0]):\n",
        "  unavailable_dates.append(set(dates_df.expected_dates.loc[i]) - set([pd.to_datetime(x) for x in dates_df.unique_dates.loc[i]]))"
      ],
      "id": "ZEMzyACB_iuy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "GG9xkb5QA39w",
        "outputId": "10c09d62-9641-4ec5-c43e-0886936a5c7c"
      },
      "source": [
        "dates_df['not_available'] = unavailable_dates \n",
        "dates_df.head()"
      ],
      "id": "GG9xkb5QA39w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile</th>\n",
              "      <th>n_unique_dates</th>\n",
              "      <th>unique_dates</th>\n",
              "      <th>min_date</th>\n",
              "      <th>max_date</th>\n",
              "      <th>expected_dates</th>\n",
              "      <th>not_available</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-06-20T00:00:00.000000000, 2017-05-14T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-25T00:00:00.000000000, 2017-07-23T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>76</td>\n",
              "      <td>[2017-07-08T00:00:00.000000000, 2017-07-05T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-10-03T00:00:00.000000000, 2017-10-13T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-27</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>38</td>\n",
              "      <td>[2017-05-11T00:00:00.000000000, 2017-05-21T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-27</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   tile  ...  not_available\n",
              "0     1  ...             {}\n",
              "1     2  ...             {}\n",
              "2     3  ...             {}\n",
              "3     4  ...             {}\n",
              "4     5  ...             {}\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "sVLkFapfCy5N",
        "outputId": "37928e88-9e4a-4fc6-eee4-5556d8d617ab"
      },
      "source": [
        "# Investigate tiles which dont have all the days\n",
        "dates_df[dates_df.not_available != set()]"
      ],
      "id": "sVLkFapfCy5N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tile</th>\n",
              "      <th>n_unique_dates</th>\n",
              "      <th>unique_dates</th>\n",
              "      <th>min_date</th>\n",
              "      <th>max_date</th>\n",
              "      <th>expected_dates</th>\n",
              "      <th>not_available</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>39</td>\n",
              "      <td>68</td>\n",
              "      <td>[2017-11-15T00:00:00.000000000, 2017-11-17T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{2017-06-30 00:00:00, 2017-11-27 00:00:00}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>186</td>\n",
              "      <td>65</td>\n",
              "      <td>[2017-11-15T00:00:00.000000000, 2017-08-07T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{2017-06-20 00:00:00, 2017-06-30 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>601</td>\n",
              "      <td>68</td>\n",
              "      <td>[2017-11-10T00:00:00.000000000, 2017-11-05T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{2017-06-30 00:00:00, 2017-11-27 00:00:00}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1823</th>\n",
              "      <td>1824</td>\n",
              "      <td>74</td>\n",
              "      <td>[2017-11-20T00:00:00.000000000, 2017-11-17T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{2017-06-30 00:00:00}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2290</th>\n",
              "      <td>2291</td>\n",
              "      <td>62</td>\n",
              "      <td>[2017-10-31T00:00:00.000000000, 2017-11-05T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{2017-06-20 00:00:00, 2017-11-17 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2515</th>\n",
              "      <td>2516</td>\n",
              "      <td>73</td>\n",
              "      <td>[2017-08-17T00:00:00.000000000, 2017-09-08T00:...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{2017-06-30 00:00:00}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3229</th>\n",
              "      <td>580</td>\n",
              "      <td>62</td>\n",
              "      <td>[2017-06-23, 2017-06-13, 2017-05-21, 2017-06-0...</td>\n",
              "      <td>2017-04-01</td>\n",
              "      <td>2017-11-30</td>\n",
              "      <td>[2017-04-01 00:00:00, 2017-04-11 00:00:00, 201...</td>\n",
              "      <td>{2017-06-20 00:00:00, 2017-11-17 00:00:00, 201...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tile  ...                                      not_available\n",
              "38      39  ...         {2017-06-30 00:00:00, 2017-11-27 00:00:00}\n",
              "185    186  ...  {2017-06-20 00:00:00, 2017-06-30 00:00:00, 201...\n",
              "600    601  ...         {2017-06-30 00:00:00, 2017-11-27 00:00:00}\n",
              "1823  1824  ...                              {2017-06-30 00:00:00}\n",
              "2290  2291  ...  {2017-06-20 00:00:00, 2017-11-17 00:00:00, 201...\n",
              "2515  2516  ...                              {2017-06-30 00:00:00}\n",
              "3229   580  ...  {2017-06-20 00:00:00, 2017-11-17 00:00:00, 201...\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkcAjlCs77s6",
        "outputId": "25c94c77-2e05-4fcc-e7f4-0efdec6d7c62"
      },
      "source": [
        "n_v_tiles = dates_df[dates_df.not_available != set()].tile.unique().tolist()\n",
        "n_v_tiles "
      ],
      "id": "AkcAjlCs77s6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[39, 186, 601, 1824, 2291, 2516, 580]"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdddc229-eb18-424e-8bce-0b1a0ac7cbc4"
      },
      "source": [
        "tile_ids_train = competition_train_df['tile_id'].nunique()"
      ],
      "id": "fdddc229-eb18-424e-8bce-0b1a0ac7cbc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ba16fdd-0d81-4661-aab9-e95d6156f329"
      },
      "source": [
        "# Our goal is developing a pixel-based Random Forest model. So we will create an X variable\n",
        "# that each row is a pixel and each column is one of the observations. \n",
        "# The other variables is y which has rows equal to the number of pixels. \n",
        "X = np.empty((0, 13 * 25))\n",
        "y = np.empty((0, 1))\n",
        "field_ids = np.empty((0, 1))\n",
        "\n",
        "for tile_id in tile_ids_train:\n",
        "    tile_df = competition_train_df[competition_train_df['tile_id']==tile_id]\n",
        "\n",
        "    label_src = rasterio.open(tile_df[tile_df['asset']=='labels']['file_path'].values[0])\n",
        "    label_array = label_src.read(1)\n",
        "    y = np.append(y, label_array.flatten())\n",
        "\n",
        "    field_id_src = rasterio.open(tile_df[tile_df['asset']=='field_ids']['file_path'].values[0])\n",
        "    field_id_array = field_id_src.read(1)\n",
        "    field_ids = np.append(field_ids, field_id_array.flatten())\n",
        "\n",
        "    tile_date_times = sorted(tile_df[tile_df['satellite_platform']=='s2']['datetime'].unique()))\n",
        "    if tile_id in n_v_tiles:\n",
        "      tile_date_times = [x[0] for x in np.array_split(sorted(tile_df[tile_df['satellite_platform']=='s2']['datetime'].unique()), 25)]\n",
        "    elif: tile_date_times[0] == np.datetime64('2017-04-01'):\n",
        "      tile_date_times = dates_1.copy()\n",
        "    else:\n",
        "      tile_date_times = dates_2.copy()\n",
        "\n",
        "    X_tile = np.empty((256 * 256, 0))\n",
        "    for date_time in tile_date_times:\n",
        "\n",
        "      b1_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B01')]['file_path'].values[0])\n",
        "      b1_array = np.expand_dims(b1_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b2_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B02')]['file_path'].values[0])\n",
        "      b2_array = np.expand_dims(b2_src.read(1).flatten(), axis=1)\n",
        "      \n",
        "      b3_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B03')]['file_path'].values[0])\n",
        "      b3_array = np.expand_dims(b3_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b4_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B04')]['file_path'].values[0])\n",
        "      b4_array = np.expand_dims(b4_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b5_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B05')]['file_path'].values[0])\n",
        "      b5_array = np.expand_dims(b5_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b6_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B06')]['file_path'].values[0])\n",
        "      b6_array = np.expand_dims(b6_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b7_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B07')]['file_path'].values[0])\n",
        "      b7_array = np.expand_dims(b7_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b8_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B08')]['file_path'].values[0])\n",
        "      b8_array = np.expand_dims(b8_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b8a_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B8A')]['file_path'].values[0])\n",
        "      b8a_array = np.expand_dims(b8a_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b9_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B09')]['file_path'].values[0])\n",
        "      b9_array = np.expand_dims(b9_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b11_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B11')]['file_path'].values[0])\n",
        "      b11_array = np.expand_dims(b11_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b12_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B12')]['file_path'].values[0])\n",
        "      b12_array = np.expand_dims(b12_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      clm_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='CLM')]['file_path'].values[0])\n",
        "      clm_array = np.expand_dims(clm_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      X_tile = np.append(X_tile, b1_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b2_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b3_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b4_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b5_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b6_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b7_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b8_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b8a_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b9_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b11_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b12_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, clm_array, axis = 1)\n",
        "\n",
        "  X = np.append(X, X_tile, axis=0)"
      ],
      "id": "3ba16fdd-0d81-4661-aab9-e95d6156f329",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b2543fe-4450-4515-bdab-160e7d206069"
      },
      "source": [
        "train_data = pd.DataFrame(X)\n",
        "train_data['crop_type'] = y.astype(int)\n",
        "train_data['Field ID'] = field_ids\n",
        "train_data = train_data[train_data.label != 0] #this filters the pixels that don't have a label (or corresponding field ID)\n",
        "train_grouped = train_data.groupby('Field ID').mean().reset_index()"
      ],
      "id": "9b2543fe-4450-4515-bdab-160e7d206069",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oLrOD53LuAc"
      },
      "source": [
        "tile_ids_test = competition_test_df['tile_id'].nunique()"
      ],
      "id": "9oLrOD53LuAc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bdxrsj7eLt9u"
      },
      "source": [
        "# Our goal is developing a pixel-based Random Forest model. So we will create an X variable\n",
        "# that each row is a pixel and each column is one of the observations.  \n",
        "X = np.empty((0, 13 * 25))\n",
        "field_ids = np.empty((0, 1))\n",
        "\n",
        "for tile_id in tile_ids_test:\n",
        "    tile_df = competition_test_df[competition_test_df['tile_id']==tile_id]\n",
        "\n",
        "    field_id_src = rasterio.open(tile_df[tile_df['asset']=='field_ids']['file_path'].values[0])\n",
        "    field_id_array = field_id_src.read(1)\n",
        "    field_ids = np.append(field_ids, field_id_array.flatten())\n",
        "\n",
        "    tile_date_times = sorted(tile_df[tile_df['satellite_platform']=='s2']['datetime'].unique()))\n",
        "    if tile_id in n_v_tiles:\n",
        "      tile_date_times = [x[0] for x in np.array_split(sorted(tile_df[tile_df['satellite_platform']=='s2']['datetime'].unique()), 25)]\n",
        "    elif: tile_date_times[0] == np.datetime64('2017-04-01'):\n",
        "      tile_date_times = dates_1.copy()\n",
        "    else:\n",
        "      tile_date_times = dates_2.copy()\n",
        "\n",
        "    X_tile = np.empty((256 * 256, 0))\n",
        "    for date_time in tile_date_times:\n",
        "\n",
        "      b1_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B01')]['file_path'].values[0])\n",
        "      b1_array = np.expand_dims(b1_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b2_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B02')]['file_path'].values[0])\n",
        "      b2_array = np.expand_dims(b2_src.read(1).flatten(), axis=1)\n",
        "      \n",
        "      b3_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B03')]['file_path'].values[0])\n",
        "      b3_array = np.expand_dims(b3_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b4_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B04')]['file_path'].values[0])\n",
        "      b4_array = np.expand_dims(b4_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b5_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B05')]['file_path'].values[0])\n",
        "      b5_array = np.expand_dims(b5_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b6_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B06')]['file_path'].values[0])\n",
        "      b6_array = np.expand_dims(b6_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b7_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B07')]['file_path'].values[0])\n",
        "      b7_array = np.expand_dims(b7_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b8_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B08')]['file_path'].values[0])\n",
        "      b8_array = np.expand_dims(b8_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b8a_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B8A')]['file_path'].values[0])\n",
        "      b8a_array = np.expand_dims(b8a_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b9_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B09')]['file_path'].values[0])\n",
        "      b9_array = np.expand_dims(b9_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b11_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B11')]['file_path'].values[0])\n",
        "      b11_array = np.expand_dims(b11_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      b12_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='B12')]['file_path'].values[0])\n",
        "      b12_array = np.expand_dims(b12_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      clm_src = rasterio.open(tile_df[(tile_df['datetime']==date_time) & (tile_df['asset']=='CLM')]['file_path'].values[0])\n",
        "      clm_array = np.expand_dims(clm_src.read(1).flatten(), axis=1)\n",
        "\n",
        "      X_tile = np.append(X_tile, b1_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b2_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b3_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b4_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b5_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b6_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b7_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b8_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b8a_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b9_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b11_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, b12_array, axis = 1)\n",
        "      X_tile = np.append(X_tile, clm_array, axis = 1)\n",
        "\n",
        "  X = np.append(X, X_tile, axis=0)"
      ],
      "id": "Bdxrsj7eLt9u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmR10SyFLt7K"
      },
      "source": [
        "test_data = pd.DataFrame(X)\n",
        "test_data['Field ID'] = field_ids\n",
        "test_data['crop_type'] = 0\n",
        "test_grouped = test_data.groupby('Field ID').mean().reset_index()"
      ],
      "id": "ZmR10SyFLt7K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0YTERkNN9HY"
      },
      "source": [
        "df = pd.concat([train_data, test_data]).reset_index(drop = True)"
      ],
      "id": "O0YTERkNN9HY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjEkEwrJOXWE"
      },
      "source": [
        "df.to_csv('radiant_pixels.csv', index = False)"
      ],
      "id": "OjEkEwrJOXWE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiDIOeXyOXTG"
      },
      "source": [
        ""
      ],
      "id": "qiDIOeXyOXTG",
      "execution_count": null,
      "outputs": []
    }
  ]
}